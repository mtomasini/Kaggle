{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle's tutorial to natural language processing\n",
    "In this notebook I will follow the tutorial found at https://www.kaggle.com/code/philculliton/nlp-getting-started-tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Datasets/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"../Datasets/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does out data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>144</td>\n",
       "      <td>accident</td>\n",
       "      <td>UK</td>\n",
       "      <td>.@NorwayMFA #Bahrain police had previously die...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>145</td>\n",
       "      <td>accident</td>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>I still have not heard Church Leaders of Kenya...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>146</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Instagram - @heyimginog</td>\n",
       "      <td>@afterShock_DeLo scuf ps live and the game... cya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>149</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'The man who can drive himself further once th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>151</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/yN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>153</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'There is no victory at bargain basement price...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>156</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>US</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>157</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'Nobody remembers who came in second.' Charles...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>158</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Instagram - @heyimginog</td>\n",
       "      <td>@afterShock_DeLo im speaking from someone that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>159</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>304</td>\n",
       "      <td>'The harder the conflict the more glorious the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>160</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#GrowingUpSpoiled going clay pigeon shooting a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>161</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Somewhere Only We Know ?</td>\n",
       "      <td>So i guess no one actually wants any free Afte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>162</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock was the most terrifying best roller...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>163</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Aftershock https://t.co/xMWODFMtUI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>164</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/M4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>165</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>US</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>168</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/e1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>170</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>dope show</td>\n",
       "      <td>@KJForDays I'm seeing them and Issues at after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>171</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/TH...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>172</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/TH...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>173</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Oshawa, Canada</td>\n",
       "      <td>#WisdomWed BONUS - 5 Minute Daily Habits that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     keyword                  location  \\\n",
       "100  144    accident                        UK   \n",
       "101  145    accident            Nairobi, Kenya   \n",
       "102  146  aftershock  Instagram - @heyimginog    \n",
       "103  149  aftershock                       304   \n",
       "104  151  aftershock               Switzerland   \n",
       "105  153  aftershock                       304   \n",
       "106  156  aftershock                        US   \n",
       "107  157  aftershock                       304   \n",
       "108  158  aftershock  Instagram - @heyimginog    \n",
       "109  159  aftershock                       304   \n",
       "110  160  aftershock                       NaN   \n",
       "111  161  aftershock  Somewhere Only We Know ?   \n",
       "112  162  aftershock                       NaN   \n",
       "113  163  aftershock                   Belgium   \n",
       "114  164  aftershock               Switzerland   \n",
       "115  165  aftershock                        US   \n",
       "116  168  aftershock                       NaN   \n",
       "117  170  aftershock                 dope show   \n",
       "118  171  aftershock               Switzerland   \n",
       "119  172  aftershock               Switzerland   \n",
       "120  173  aftershock            Oshawa, Canada   \n",
       "\n",
       "                                                  text  target  \n",
       "100  .@NorwayMFA #Bahrain police had previously die...       1  \n",
       "101  I still have not heard Church Leaders of Kenya...       0  \n",
       "102  @afterShock_DeLo scuf ps live and the game... cya       0  \n",
       "103  'The man who can drive himself further once th...       0  \n",
       "104  320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/yN...       0  \n",
       "105  'There is no victory at bargain basement price...       0  \n",
       "106  320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...       0  \n",
       "107  'Nobody remembers who came in second.' Charles...       0  \n",
       "108  @afterShock_DeLo im speaking from someone that...       0  \n",
       "109  'The harder the conflict the more glorious the...       0  \n",
       "110  #GrowingUpSpoiled going clay pigeon shooting a...       0  \n",
       "111  So i guess no one actually wants any free Afte...       0  \n",
       "112  Aftershock was the most terrifying best roller...       0  \n",
       "113                 Aftershock https://t.co/xMWODFMtUI       0  \n",
       "114  320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/M4...       0  \n",
       "115  320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...       0  \n",
       "116  320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/e1...       0  \n",
       "117  @KJForDays I'm seeing them and Issues at after...       0  \n",
       "118  320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/TH...       0  \n",
       "119  320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/TH...       0  \n",
       "120  #WisdomWed BONUS - 5 Minute Daily Habits that ...       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.columns)\n",
    "train_df.loc[100:120, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 4 explanatory variables: `id` is a simple ID that will clearly be removed; `keyword` relates to the word that was picked up by the algorithm that needs to classify tweets (or similar); `location` is sometimes a place, sometimes a number, sometimes another reference (_e.g_ Instagram); finally, `text` refers to the actual text. The response variable is `target`, which is either 1 (for a disaster tweet) or 0 (for an unrelated tweet.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building vectors\n",
    "We use `CountVectorizer` to count the words in each tweet and turn them into processable data (_i.e._ vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_train_vectors[0].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`example_train_vectors` contains information about how many tokens (unique words) there are in the first 5 tweets -- in this case it's the length of the vector. Then, each tweet is rewritten as a vector of 0 (when the word isn't in the tweet) and 1 (when the word is in the tweet). Let's process all data like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "# to have the same vectors in the test_vectors, we use transform instead of fit_transform\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 21637)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors[0].todense().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "We assume there is a linear connection between the words in a tweet and their target. Since our vectors are quite big (21637 tokens detected), we build a ridge regression model to have our weights go to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `cross-validation` to validate the model with the rest. This competition has F1 as metric.\n",
    "\n",
    "### The $F_1$ metric\n",
    "The $F_1$ metric is constructed from precision and recall. In pattern recognition, \"precision\"  is the fraction of relevant instances among the retrieved instances. In this case it's the sum of all `True` versus the total number of data. \"Recall\" is the fraction of relevant instances that were retrieved, compared to the actual number of relevant instances that would be available. Note that recall cannot be calculated in real life, but through cross-validation (and thus knowing the total sample) we can measure it. Then, taken these two quantities, $F_1$ is the harmonic means of these two quantities, that is\n",
    "\n",
    "$$\n",
    "F_1 = \\frac{2}{\\text{recall}^{-1} + \\text{precision}^{-1}}\n",
    "$$\n",
    "\n",
    "Let's do cross validation for $F_1$ on our ridge classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59421842, 0.56498283, 0.64149093])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the challenge I will attempt to improve from this value (which will be around 60-65%). Time to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../Datasets/nlp-getting-started/sample_submission.csv\")\n",
    "\n",
    "sample_submission[\"target\"] = clf.predict(test_vectors)\n",
    "sample_submission.to_csv(\"tutorial_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resulted in a score of about 0.78! Nice. I'm 548/730 in the range (bottom 25%). Time to try and improve this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('machinelearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25ad6a4be8b7cb5307e079b5c70053dc031a1417502bda203100eef0d9318af0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
